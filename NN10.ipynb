{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a270c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e26272d",
   "metadata": {},
   "source": [
    "# E : 10-4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9191af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(x, y):\n",
    "    return 1 - 2*x - 2*y + x**2 + 2*x*y + y**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e88e45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a 200x1 vector of values for x and y axes\n",
    "pointsX = np.linspace(-10, 10, num=200)\n",
    "pointsY = np.linspace(-10, 10, num=200)\n",
    "\n",
    "# Create a 200x200 grid of points\n",
    "myGridX, myGridY = np.meshgrid(pointsX, pointsY)\n",
    "myGrid = np.column_stack((myGridX.flatten(), myGridY.flatten()))\n",
    "\n",
    "# Map all possible combinations of the grid through the function\n",
    "z = np.vectorize(fun)(myGrid[:, 0], myGrid[:, 1])\n",
    "\n",
    "# Extract x, y, and z values from the grid\n",
    "x = myGrid[:, 0]\n",
    "y = myGrid[:, 1]\n",
    "\n",
    "# Create a 3D mesh plot using plotly\n",
    "fig = go.Figure(data=go.Mesh3d(x=x, y=y, z=z, intensity=z, colorscale=\"Viridis\"))\n",
    "fig.show()\n",
    "\n",
    "# Create a contour plot using matplotlib and ggplot\n",
    "plt.tricontourf(x, y, z, cmap=\"viridis\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a94ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b39171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([[1, 1], [1, 1]])  # Create a 2x2 matrix R\n",
    "H = 2 * R  # Multiply R by 2 to get H\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(R)  # Compute eigenvalues and eigenvectors\n",
    "\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\")\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b94bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = np.array([[2, 2], [2, 2]])  # Create a 2x2 matrix H\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(H)  # Compute eigenvalues and eigenvectors\n",
    "\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\")\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad1fc3",
   "metadata": {},
   "source": [
    "III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LMS(init, bias, learning_rate, input, expect, max_iter, tol, mask, use_bias):\n",
    "    n = input.shape[1]\n",
    "    w = init\n",
    "    b = bias\n",
    "    \n",
    "    for i in range(1, max_iter + 1):  # loop over iterations\n",
    "        if not mask:  # if the user does want to print out statements\n",
    "            print(\" Iteration\", i)\n",
    "        \n",
    "        for j in range(n):  # loop over input vectors\n",
    "            if use_bias:  # does the user want to include a bias\n",
    "                a = np.dot(w, input[:, j]) + b\n",
    "            else:\n",
    "                a = np.dot(w, input[:, j])\n",
    "            \n",
    "            e = expect[j] - a\n",
    "            w = w + 2 * learning_rate * np.outer(e, input[:, j])\n",
    "            \n",
    "            if use_bias:\n",
    "                b = b + 2 * learning_rate * e\n",
    "            \n",
    "            if not mask:  # if the user does want to print out statements\n",
    "                print(\"INPUT VECTOR:\", j)\n",
    "                print(\"a value:\", a)\n",
    "                print(\"error value:\", e)\n",
    "                print(\"new weight value:\", w)\n",
    "                print(\"new bias value:\", b)\n",
    "        \n",
    "        error = 0\n",
    "        for j in range(n):\n",
    "            if use_bias:  # does the user want to include a bias\n",
    "                a = np.dot(w, input[:, j]) + b\n",
    "            else:\n",
    "                a = np.dot(w, input[:, j])\n",
    "            \n",
    "            e = expect[j] - a\n",
    "            error = error + e ** 2\n",
    "        \n",
    "        # if the square root of the sum of the square errors is greater than the tol, then algo has not converged\n",
    "        converged = 1\n",
    "        if np.sqrt(error) > tol:\n",
    "            converged = 0\n",
    "        \n",
    "        if converged:\n",
    "            print(\" Algorithm CONVERGED:\")\n",
    "            print(\"Current weight is:\", w)\n",
    "            \n",
    "            if use_bias:  # does the user want to include a bias\n",
    "                print(\"Current bias is:\", b)\n",
    "            \n",
    "            print(\"Iterations taken:\", i)\n",
    "            \n",
    "            if use_bias:  # does the user want to include a bias\n",
    "                return {\"w\": w, \"b\": b}\n",
    "            \n",
    "            return {\"w\": w}\n",
    "    \n",
    "    error = 0\n",
    "    for j in range(n):\n",
    "        a = np.dot(w, input[:, j]) + b\n",
    "        e = expect[j] - a\n",
    "        error = error + abs(e)\n",
    "    \n",
    "    print(\"MAXIMUM ITERATIONS REACHED\")\n",
    "    print(\"Current weight is:\", w)\n",
    "    \n",
    "    if use_bias:  # does the user want to include a bias\n",
    "        print(\"Current bias is:\", b)\n",
    "    \n",
    "    print(\"Iterations taken:\", i)\n",
    "    print(\"ERROR:\", error)\n",
    "    \n",
    "    if use_bias:  # does the user want to include a bias\n",
    "        return {\"w\": w, \"b\": b}\n",
    "    \n",
    "    return {\"w\": w}\n",
    "\n",
    "init = np.array([0, 0])\n",
    "input_matrix = np.array([[1, 1], [-1, -1]])\n",
    "expected = np.array([1, -1])\n",
    "val = LMS(init, 0, 0.20, input_matrix, expected, 100, 1e-10, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = LMS(init, 0, 0.3, input, expected, 100, 1e-10, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab46b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init = np.array([[1, 1]])\n",
    "val = LMS(init, 1, 0.2, input, expected, 100, 1e-10, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0528944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'p1': [1, -1], 'p2': [1, -1], 't': [1, -1]})\n",
    "\n",
    "# Create a scatter plot with seaborn\n",
    "sns.scatterplot(data=data, x='p1', y='p2', hue='t', size=2)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Plot of p1, p2, and decision boundary\")\n",
    "\n",
    "# Add horizontal and vertical lines\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "\n",
    "# Add the decision boundary line\n",
    "plt.plot([-1, 1], [1, -1], color='black', linestyle='--')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394cb95e",
   "metadata": {},
   "source": [
    "# Sec E : 10-6 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaaf1d5",
   "metadata": {},
   "source": [
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a138704a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f03f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def LMS(init, bias, learning_rate, input_data, expect, max_iter, tol, mask, use_bias):\n",
    "    n = input_data.shape[1]\n",
    "    w = init\n",
    "    b = bias\n",
    "    \n",
    "    for i in range(1, max_iter + 1):  # loop over iterations\n",
    "        if not mask:  # if the user does want to print out statements\n",
    "            print(f\"Iteration {i}\")\n",
    "        \n",
    "        for j in range(n):  # loop over input vectors\n",
    "            if use_bias:  # does the user want to include a bias\n",
    "                a = np.dot(w, input_data[:, j]) + b\n",
    "            else:\n",
    "                a = np.dot(w, input_data[:, j])\n",
    "            \n",
    "            e = expect[j] - a\n",
    "            w = w + 2 * learning_rate * np.outer(e, input_data[:, j])\n",
    "            \n",
    "            if use_bias:\n",
    "                b = b + 2 * learning_rate * e\n",
    "            \n",
    "            if not mask:  # if the user does want to print out statements\n",
    "                print(f\"INPUT VECTOR: {j}\")\n",
    "                print(\"a value:\")\n",
    "                print(a)\n",
    "                print(\"error value:\")\n",
    "                print(e)\n",
    "                print(\"new weight value:\")\n",
    "                print(w)\n",
    "                print(\"new bias value:\")\n",
    "                print(b)\n",
    "        \n",
    "        error = 0\n",
    "        for j in range(n):\n",
    "            if use_bias:  # does the user want to include a bias\n",
    "                a = np.dot(w, input_data[:, j]) + b\n",
    "            else:\n",
    "                a = np.dot(w, input_data[:, j])\n",
    "            \n",
    "            e = expect[j] - a\n",
    "            error = error + e**2\n",
    "        \n",
    "        converged = 1\n",
    "        if np.sqrt(error) > tol:\n",
    "            converged = 0\n",
    "        \n",
    "        if converged:\n",
    "            print(\"Algorithm CONVERGED:\")\n",
    "            print(\"Current weight is:\", w)\n",
    "            \n",
    "            if use_bias:  # does the user want to include a bias\n",
    "                print(\"Current bias is:\", b)\n",
    "            \n",
    "            print(f\"Iterations taken: {i}\")\n",
    "            \n",
    "            if use_bias:  # does the user want to include a bias\n",
    "                return {\"w\": w, \"b\": b}\n",
    "            \n",
    "            return {\"w\": w}\n",
    "    \n",
    "    error = 0\n",
    "    for j in range(n):\n",
    "        a = np.dot(w, input_data[:, j]) + b\n",
    "        e = expect[j] - a\n",
    "        error = error + abs(e)\n",
    "    \n",
    "    print(\"MAXIMUM ITERATIONS REACHED\")\n",
    "    print(\"Current weight is:\", w)\n",
    "    \n",
    "    if use_bias:  # does the user want to include a bias\n",
    "        print(\"Current bias is:\", b)\n",
    "    \n",
    "    print(f\"Iterations taken: {i}\")\n",
    "    print(\"ERROR:\")\n",
    "    print(error)\n",
    "    \n",
    "    if use_bias:  # does the user want to include a bias\n",
    "        return {\"w\": w, \"b\": b}\n",
    "    \n",
    "    return {\"w\": w}\n",
    "\n",
    "init = np.array([0, 0])\n",
    "input_data = np.array([[1, 1, -1, -4], [1, 2, 0, 1]])\n",
    "expected = np.array([1, 1, -1, -1])\n",
    "val = LMS(init, 0, 0.10, input_data, expected, 1, 1e-10, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31bf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Given data\n",
    "data = pd.DataFrame({'p1': [1, -1, 0, -4], 'p2': [1, 2, -1, 1], 't': [1, 1, -1, -1]})\n",
    "\n",
    "# Plotting\n",
    "sns.scatterplot(data=data, x='p1', y='p2', hue='t', size=2)\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "plt.plot([1, -4], [2, 0], color='red', linestyle='--')  # Decision boundary line\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Plot of the two classes and decision boundary after one iteration\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b548d",
   "metadata": {},
   "source": [
    "IIII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e863772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Given data\n",
    "data = pd.DataFrame({'p1': [1, -1, 0, -4], 'p2': [1, 2, -1, 1], 't': [1, 1, -1, -1]})\n",
    "\n",
    "# Plotting\n",
    "sns.scatterplot(data=data, x='p1', y='p2', hue='t', size=2)\n",
    "plt.axhline(0, color='black', linestyle='--')\n",
    "plt.axvline(0, color='black', linestyle='--')\n",
    "plt.plot([1, -4], [2, 0], color='black', linestyle='--')  # Decision boundary line\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Plot of the two classes and decision boundary after one iteration\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960d481f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = LMS(init, 0, 0.10, input, expected, 1000, 1e-10, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = LMS(init, 0, 0.10, input, expected, 100, 1e-10, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ad405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given data\n",
    "data = pd.DataFrame({'p1': [1, -1, 0, -4], 'p2': [1, 2, -1, 1], 't': [1, 1, -1, -1]})\n",
    "\n",
    "# Plotting\n",
    "sns.scatterplot(data=data, x='p1', y='p2', hue='t', size=2)\n",
    "plt.axhline(0, color='green', linestyle='--')\n",
    "plt.axvline(0, color='green', linestyle='--')\n",
    "plt.plot([-4, 2], [0, 1], color='red', linestyle='--')  # Converged decision boundary with bias\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.title(\"Plot of the two classes and converged decision boundary with bias\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b98394d",
   "metadata": {},
   "source": [
    "# Sec E: 10_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863a5e0b",
   "metadata": {},
   "source": [
    "II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7974045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reference patterns and targets\n",
    "P = np.array([[1, 1], [1, -1]])\n",
    "T = np.array([1, -1])\n",
    "\n",
    "# Learning rate\n",
    "alpha = 0.1\n",
    "\n",
    "# Initial weights and bias\n",
    "W = np.array([0, 0])\n",
    "b = 0\n",
    "\n",
    "# Training the ADALINE network with a bias using the LMS algorithm\n",
    "for step in range(20):\n",
    "    for i in range(2):\n",
    "        a = np.dot(W, P[:, i]) + b\n",
    "        e = T[i] - a\n",
    "        W = W + 2 * alpha * e * P[:, i]\n",
    "        b = b + 2 * alpha * e\n",
    "\n",
    "# Displaying weights and bias\n",
    "print(\"Final weights:\", W)\n",
    "print(\"Final bias:\", b)\n",
    "\n",
    "# Displaying reference patterns in graph\n",
    "plt.figure()\n",
    "plt.plot(P[0, 0], P[1, 0], 'r+')\n",
    "plt.plot(P[0, 1], P[1, 1], 'r+')\n",
    "\n",
    "# Sketching the final decision boundary\n",
    "x = np.arange(-2, 2, 0.1)\n",
    "y = (-W[0] * x - b) / W[1]\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.axis([-2, 2, -2, 2])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868ba489",
   "metadata": {},
   "source": [
    "# III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069ca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reference patterns and targets\n",
    "P = np.array([[1, 1], [1, -1]])\n",
    "T = np.array([1, -1])\n",
    "\n",
    "# Learning rate\n",
    "alpha = 0.1\n",
    "\n",
    "# Initial weights and bias\n",
    "W = np.array([1, 1])\n",
    "b = 1\n",
    "\n",
    "# Training the ADALINE network with a bias using the LMS algorithm\n",
    "for step in range(20):\n",
    "    for i in range(2):\n",
    "        a = np.dot(W, P[:, i]) + b\n",
    "        e = T[i] - a\n",
    "        W = W + 2 * alpha * e * P[:, i]\n",
    "        b = b + 2 * alpha * e\n",
    "\n",
    "# Displaying weights and bias\n",
    "print(\"Final weights:\", W)\n",
    "print(\"Final bias:\", b)\n",
    "\n",
    "# Displaying reference patterns in graph\n",
    "plt.figure()\n",
    "plt.plot(P[0, 0], P[1, 0], 'r+')\n",
    "plt.plot(P[0, 1], P[1, 1], 'r+')\n",
    "\n",
    "# Sketching the final decision boundary\n",
    "x = np.arange(-2, 2, 0.1)\n",
    "y = (-W[0] * x - b) / W[1]\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.axis([-2, 2, -2, 2])\n",
    "plt.title('Decision boundary for x_0=[0 0 0]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f24747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51249d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adef7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d47346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
